{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"textAnalysis2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMGeL024q4f+JT3ub2aI3EG"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"-pI5_RdK-NFW","colab_type":"text"},"source":["N-GRAMS"]},{"cell_type":"markdown","metadata":{"id":"-657akGQ8JHX","colab_type":"text"},"source":[" \"A contiguous sequence of N items from a given sample of text or speech\". Here an item can be a character, a word or a sentence and N can be any integer. When N is 2, we call the sequence a bigram. Similarly, a sequence of 3 items is called a trigram, and so on.\n","\n","1. https://stackabuse.com/python-for-nlp-developing-an-automatic-text-filler-using-n-grams/\n","\n","2. \n"," https://kavita-ganesan.com/what-are-n-grams/#.XkJHaeHhU5k\n","\n"]},{"cell_type":"markdown","metadata":{"id":"QCUUIOzYpJgW","colab_type":"text"},"source":["3. For example, for the sentence “The cow jumps over the moon”. If N=2 (known as bigrams), then the ngrams would be:\n","\n","    the cow\n","    cow jumps\n","    jumps over\n","    over the\n","    the moon\n"]},{"cell_type":"code","metadata":{"id":"VnuLmnit-UXe","colab_type":"code","colab":{}},"source":["import re\n","from nltk.util import ngrams\n","\n","s = \"Natural-language processing (NLP) is an area of computer science \" \\\n","    \"and artificial intelligence concerned with the interactions \" \\\n","    \"between computers and human (natural) languages.\"\n","\n","s = s.lower()\n","s = re.sub(r'[^a-zA-Z0-9\\s]', ' ', s)  #optional   # re(regular expressions): https://www.tutorialspoint.com/python/python_reg_expressions.htm\n","tokens = [token for token in s.split(\" \") if token != \"\"]\n","output = list(ngrams(tokens, 5))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gdXIsXyzBJfu","colab_type":"code","outputId":"1aacb8c4-9a95-448e-9dd5-652f67fe6fbb","executionInfo":{"status":"ok","timestamp":1582001908211,"user_tz":-330,"elapsed":1165,"user":{"displayName":"Jeewanjot Kaur","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBU_yNMtx6c9l7-_aX_Oy_kyFDGn0qFXkttm68VCg=s64","userId":"12802469298261167752"}},"colab":{"base_uri":"https://localhost:8080/","height":89}},"source":["print('s',s)\n","print(s.split(\" \"))\n","print('tokens',tokens)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["s natural language processing  nlp  is an area of computer science and artificial intelligence concerned with the interactions between computers and human  natural  languages \n","['natural', 'language', 'processing', '', 'nlp', '', 'is', 'an', 'area', 'of', 'computer', 'science', 'and', 'artificial', 'intelligence', 'concerned', 'with', 'the', 'interactions', 'between', 'computers', 'and', 'human', '', 'natural', '', 'languages', '']\n","tokens ['natural', 'language', 'processing', 'nlp', 'is', 'an', 'area', 'of', 'computer', 'science', 'and', 'artificial', 'intelligence', 'concerned', 'with', 'the', 'interactions', 'between', 'computers', 'and', 'human', 'natural', 'languages']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"v3KUa6dJB8Ji","colab_type":"code","outputId":"27fd9d3a-9bef-4644-a0ba-162c72a8fac5","executionInfo":{"status":"ok","timestamp":1582001941219,"user_tz":-330,"elapsed":967,"user":{"displayName":"Jeewanjot Kaur","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBU_yNMtx6c9l7-_aX_Oy_kyFDGn0qFXkttm68VCg=s64","userId":"12802469298261167752"}},"colab":{"base_uri":"https://localhost:8080/","height":347}},"source":["output"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('natural', 'language', 'processing', 'nlp', 'is'),\n"," ('language', 'processing', 'nlp', 'is', 'an'),\n"," ('processing', 'nlp', 'is', 'an', 'area'),\n"," ('nlp', 'is', 'an', 'area', 'of'),\n"," ('is', 'an', 'area', 'of', 'computer'),\n"," ('an', 'area', 'of', 'computer', 'science'),\n"," ('area', 'of', 'computer', 'science', 'and'),\n"," ('of', 'computer', 'science', 'and', 'artificial'),\n"," ('computer', 'science', 'and', 'artificial', 'intelligence'),\n"," ('science', 'and', 'artificial', 'intelligence', 'concerned'),\n"," ('and', 'artificial', 'intelligence', 'concerned', 'with'),\n"," ('artificial', 'intelligence', 'concerned', 'with', 'the'),\n"," ('intelligence', 'concerned', 'with', 'the', 'interactions'),\n"," ('concerned', 'with', 'the', 'interactions', 'between'),\n"," ('with', 'the', 'interactions', 'between', 'computers'),\n"," ('the', 'interactions', 'between', 'computers', 'and'),\n"," ('interactions', 'between', 'computers', 'and', 'human'),\n"," ('between', 'computers', 'and', 'human', 'natural'),\n"," ('computers', 'and', 'human', 'natural', 'languages')]"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"aaDqg0BFCpZW","colab_type":"text"},"source":["# Task : \n","1. Try to implement N-grams on article fetched from web(https://www.whitehouse.gov/briefings-statements/).(try out with spacy)\n","2. Find out various applications of N-grams. "]},{"cell_type":"markdown","metadata":{"id":"i2GCxSjrdlDY","colab_type":"text"},"source":["# Named Entity Recognition(NER)"]},{"cell_type":"markdown","metadata":{"id":"afsleUrgj5eR","colab_type":"text"},"source":["is probably the first step towards information extraction that seeks to locate and classify named entities in text into pre-defined categories such as the names of persons, organizations, locations, expressions of times, quantities, monetary values, percentages, etc.\n","1. Named Entity: It is a real-world object, such as persons, locations, organizations, products, etc., that can be denoted with a proper name."]},{"cell_type":"code","metadata":{"id":"YZzCUpQ6CKK3","colab_type":"code","colab":{}},"source":["import nltk\n","from nltk.tokenize import word_tokenize\n","from nltk.tag import pos_tag"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hVlylnpdkS9I","colab_type":"code","colab":{}},"source":["ex = 'European authorities fined Google a record $5.1 billion on Wednesday for abusing its power in the mobile phone market and ordered the company to alter its practices'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0r4CMXG8kYIZ","colab_type":"code","colab":{}},"source":["def preprocess(sent):\n","    sent = nltk.word_tokenize(sent)\n","    print('Word Tokenize:',sent)\n","    sent = nltk.pos_tag(sent)\n","    return sent"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5O_WbQdQkd7L","colab_type":"code","outputId":"5fa3ea45-5246-4efb-b01a-14b6d63d2bbf","executionInfo":{"status":"ok","timestamp":1581413289554,"user_tz":-330,"elapsed":925,"user":{"displayName":"Jeewanjot Kaur","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBU_yNMtx6c9l7-_aX_Oy_kyFDGn0qFXkttm68VCg=s64","userId":"12802469298261167752"}},"colab":{"base_uri":"https://localhost:8080/","height":541}},"source":["import nltk\n","# nltk.download('punkt')\n","# nltk.download('averaged_perceptron_tagger')\n","sent = preprocess(ex)\n","sent"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Word Tokenize: ['European', 'authorities', 'fined', 'Google', 'a', 'record', '$', '5.1', 'billion', 'on', 'Wednesday', 'for', 'abusing', 'its', 'power', 'in', 'the', 'mobile', 'phone', 'market', 'and', 'ordered', 'the', 'company', 'to', 'alter', 'its', 'practices']\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[('European', 'JJ'),\n"," ('authorities', 'NNS'),\n"," ('fined', 'VBD'),\n"," ('Google', 'NNP'),\n"," ('a', 'DT'),\n"," ('record', 'NN'),\n"," ('$', '$'),\n"," ('5.1', 'CD'),\n"," ('billion', 'CD'),\n"," ('on', 'IN'),\n"," ('Wednesday', 'NNP'),\n"," ('for', 'IN'),\n"," ('abusing', 'VBG'),\n"," ('its', 'PRP$'),\n"," ('power', 'NN'),\n"," ('in', 'IN'),\n"," ('the', 'DT'),\n"," ('mobile', 'JJ'),\n"," ('phone', 'NN'),\n"," ('market', 'NN'),\n"," ('and', 'CC'),\n"," ('ordered', 'VBD'),\n"," ('the', 'DT'),\n"," ('company', 'NN'),\n"," ('to', 'TO'),\n"," ('alter', 'VB'),\n"," ('its', 'PRP$'),\n"," ('practices', 'NNS')]"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"markdown","metadata":{"id":"FxjtrgMQv8FM","colab_type":"text"},"source":["implement noun phrase chunking to identify named entities using a regular expression consisting of rules that indicate how sentences should be chunked."]},{"cell_type":"markdown","metadata":{"id":"a7i0fH2dll4C","colab_type":"text"},"source":["#### CHUNKING:\n"," is a process of extracting phrases from unstructured text. Instead of just simple tokens which may not represent the actual meaning of the text, its advisable to use phrases such as “South Africa” as a single word instead of ‘South’ and ‘Africa’ separate words.\n","1. chunk: a group of bits of information   \n","2. https://medium.com/greyatom/learning-pos-tagging-chunking-in-nlp-85f7f811a8cb\n","\n","\n","\n"," Chunking works on top of POS tagging, it uses pos-tags as input and provides chunks as output. Similar to POS tags, there are a standard set of Chunk tags like Noun Phrase(NP), Verb Phrase (VP), etc. Chunking is very important when you want to extract information from text such as Locations, Person Names etc. In NLP called Named Entity Extraction."]},{"cell_type":"markdown","metadata":{"id":"DaulmeyUnAx_","colab_type":"text"},"source":["### Noun Phrase Chunking\n","\n","chunk pattern consists of one rule, that a noun phrase, NP, should be formed whenever the chunker finds an optional determiner, DT, followed by any number of adjectives, JJ, and then a noun, NN."]},{"cell_type":"code","metadata":{"id":"TvdvbNekkt_e","colab_type":"code","colab":{}},"source":["pattern = 'NP: {<DT>?<JJ>*<NN>}'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"n2_1oSQ8uyiT","colab_type":"code","outputId":"3fe95ddd-3915-4f21-8bab-42a480b4d7ee","executionInfo":{"status":"ok","timestamp":1581416412980,"user_tz":-330,"elapsed":1001,"user":{"displayName":"Jeewanjot Kaur","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBU_yNMtx6c9l7-_aX_Oy_kyFDGn0qFXkttm68VCg=s64","userId":"12802469298261167752"}},"colab":{"base_uri":"https://localhost:8080/","height":451}},"source":["cp = nltk.RegexpParser(pattern)\n","cs = cp.parse(sent)\n","print(cs) #The output can be read as a tree or a hierarchy with S as the first level, denoting sentence. "],"execution_count":0,"outputs":[{"output_type":"stream","text":["(S\n","  European/JJ\n","  authorities/NNS\n","  fined/VBD\n","  Google/NNP\n","  (NP a/DT record/NN)\n","  $/$\n","  5.1/CD\n","  billion/CD\n","  on/IN\n","  Wednesday/NNP\n","  for/IN\n","  abusing/VBG\n","  its/PRP$\n","  (NP power/NN)\n","  in/IN\n","  (NP the/DT mobile/JJ phone/NN)\n","  (NP market/NN)\n","  and/CC\n","  ordered/VBD\n","  (NP the/DT company/NN)\n","  to/TO\n","  alter/VB\n","  its/PRP$\n","  practices/NNS)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uay5Qkm5vXpe","colab_type":"code","outputId":"b1b0a077-d8d7-46f8-b480-fb051c08aabd","executionInfo":{"status":"ok","timestamp":1581417418784,"user_tz":-330,"elapsed":961,"user":{"displayName":"Jeewanjot Kaur","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBU_yNMtx6c9l7-_aX_Oy_kyFDGn0qFXkttm68VCg=s64","userId":"12802469298261167752"}},"colab":{"base_uri":"https://localhost:8080/","height":503}},"source":["from nltk.chunk import conlltags2tree, tree2conlltags #CoNLL, the Conference on Natural Language Learning, is SIGNLL's yearly meeting.\n","from pprint import pprint\n","iob_tagged = tree2conlltags(cs) #Convert a tree to the CoNLL IOB tag format.\n","pprint(iob_tagged) # input output beggining tag\n","\n","#The B- prefix before a tag indicates that the tag is the beginning of a chunk, and an I- prefix before a tag indicates that the tag is inside a chunk. \n","# An O tag indicates that a token belongs to no chunk. "],"execution_count":0,"outputs":[{"output_type":"stream","text":["[('European', 'JJ', 'O'),\n"," ('authorities', 'NNS', 'O'),\n"," ('fined', 'VBD', 'O'),\n"," ('Google', 'NNP', 'O'),\n"," ('a', 'DT', 'B-NP'),\n"," ('record', 'NN', 'I-NP'),\n"," ('$', '$', 'O'),\n"," ('5.1', 'CD', 'O'),\n"," ('billion', 'CD', 'O'),\n"," ('on', 'IN', 'O'),\n"," ('Wednesday', 'NNP', 'O'),\n"," ('for', 'IN', 'O'),\n"," ('abusing', 'VBG', 'O'),\n"," ('its', 'PRP$', 'O'),\n"," ('power', 'NN', 'B-NP'),\n"," ('in', 'IN', 'O'),\n"," ('the', 'DT', 'B-NP'),\n"," ('mobile', 'JJ', 'I-NP'),\n"," ('phone', 'NN', 'I-NP'),\n"," ('market', 'NN', 'B-NP'),\n"," ('and', 'CC', 'O'),\n"," ('ordered', 'VBD', 'O'),\n"," ('the', 'DT', 'B-NP'),\n"," ('company', 'NN', 'I-NP'),\n"," ('to', 'TO', 'O'),\n"," ('alter', 'VB', 'O'),\n"," ('its', 'PRP$', 'O'),\n"," ('practices', 'NNS', 'O')]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"U6NE-ymS11-P","colab_type":"text"},"source":["With the function nltk.ne_chunk(), we can recognize named entities using a classifier, the classifier adds category labels such as PERSON, ORGANIZATION, and GPE."]},{"cell_type":"code","metadata":{"id":"MVhdbxzoyKkN","colab_type":"code","outputId":"7efca62d-4283-42ee-fe55-99c34de6d196","executionInfo":{"status":"ok","timestamp":1581418086100,"user_tz":-330,"elapsed":1010,"user":{"displayName":"Jeewanjot Kaur","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBU_yNMtx6c9l7-_aX_Oy_kyFDGn0qFXkttm68VCg=s64","userId":"12802469298261167752"}},"colab":{"base_uri":"https://localhost:8080/","height":521}},"source":["from nltk import ne_chunk\n","# nltk.download('maxent_ne_chunker')\n","# nltk.download('words')\n","ne_tree = ne_chunk(pos_tag(word_tokenize(ex)))\n","print(ne_tree)#Geo-Political Entity"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(S\n","  (GPE European/JJ)\n","  authorities/NNS\n","  fined/VBD\n","  (PERSON Google/NNP)\n","  a/DT\n","  record/NN\n","  $/$\n","  5.1/CD\n","  billion/CD\n","  on/IN\n","  Wednesday/NNP\n","  for/IN\n","  abusing/VBG\n","  its/PRP$\n","  power/NN\n","  in/IN\n","  the/DT\n","  mobile/JJ\n","  phone/NN\n","  market/NN\n","  and/CC\n","  ordered/VBD\n","  the/DT\n","  company/NN\n","  to/TO\n","  alter/VB\n","  its/PRP$\n","  practices/NNS)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2gGt6Nqj3V6v","colab_type":"text"},"source":["## Task \n","1. implement on article from whitehouse press briefing\n"]},{"cell_type":"markdown","metadata":{"id":"SjuDLIQU3WC_","colab_type":"text"},"source":["# String Matching\n","\n","In computer science, fuzzy string matching is the technique of finding strings that match a pattern approximately (rather than exactly). In another word, fuzzy string matching is a type of search that will find matches even when users misspell words or enter only partial words for the search. It is also known as approximate string matching.\n","\n","1. https://towardsdatascience.com/natural-language-processing-for-fuzzy-string-matching-with-python-6632b7824c49\n","2. A spell checker and spelling-error, typos corrector. For example, a user types “Missisaga” into Google, a list of hits is returned along with “Showing results for mississauga”. That is, search query returns results even if the user input contains additional or missing characters, or other types of spelling error.\n","3. Fuzzywuzzy is a Python library uses Levenshtein Distance to calculate the differences between sequences in a simple-to-use package.\n","4. Levenshtein distance:  is a string metric for measuring the difference between two sequences. Informally, the Levenshtein distance between two words is the minimum number of single-character edits (insertions, deletions or substitutions) required to change one word into the other. "]},{"cell_type":"code","metadata":{"id":"RocsPjOJ2FwN","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}